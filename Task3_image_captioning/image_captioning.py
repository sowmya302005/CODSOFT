from transformers import pipeline
from PIL import Image

print("ğŸš€ Loading lightweight model... (this may take a minute the first time)")
captioner = pipeline("image-to-text", model="nlpconnect/vit-gpt2-image-captioning")

# Ask for image input
image_path = input("\nğŸ“ Enter the full path to your image: ")

try:
    image = Image.open(image_path)
except Exception as e:
    print("âŒ Could not open image:", e)
    exit()

print("\nâœ¨ Generating caption...")
captions = captioner(image)

print("\nğŸ–¼ï¸ Caption Generated:")
print("ğŸ‘‰", captions[0]['generated_text'])
